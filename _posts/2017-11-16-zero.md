---
layout: post
title: ゼロから作るDeep Learning
category: dl
---

* パーセプトロン
  * ある入力に対して決まった出力を返す
  * 重みとバイアスをパラメータとする
  * 単層→線形領域。多層→非線形領域→コンピュータ

* NN
  * 活性化関数→シグモイド、ReLU
  * 出力層の活性化関数
    * 回帰問題→恒等関数
    * 分類問題→ソフトマックス関数
  * 分類問題では出力層のニューロンの数＝分類するクラス数
  * バッチ→一括して扱う入力データ

* NNの学習
  * 訓練データで学習→テストデータで学習したモデルの汎化能力を評価
  * 損失関数を定義し、その値が小さくなるように重みパラメータを更新する
  * 更新する際は勾配方向に更新する
  * 勾配を求める方法
    * 数値微分→計算時間はかかるが実装は簡単
    * 誤差逆伝搬法→複雑だが高速、計算グラフの逆伝搬によって各ノードの微分を求める
  * 二つの結果を比較し誤りがないことを確認する

* 学習のテク
  * パラメータの更新方法→SGD,Momentum,AdaGrad,Adam
  * 重みの初期値の与え方は正しい学習を行う上で重要であり,Xavier,Heなどがある
  * Batch Normalization→学習速度を上げ、初期値に依存しなくなる 
  * 過学習を抑制する→Weight decay,Dropout
  * ハイパーパラメータの探索はいい値が存在する範囲を徐々に絞ると効率がいい

* CNN
  * 従来の全結合層のネットワークに対して畳み込み層とプーリング層が加わる
  * 層が深くなるにつれて高度な情報が抽出される

* NNの実装
  * NumPy(多次元配列を扱うライブラリ)で効率よく実装できる
  * 各レイヤのクラスに対して順伝搬と逆伝搬の処理を定義
  * 畳み込み層とプーリング層はim2col(画像を行列に展開する関数)を用いるとシンプルで効率的に実装できる

* DL
  * 多くの問題ではネットワークを深くすることで性能が向上する
  * GPU・分散学習・ビット精度の削減により高速化できる
  * 物体認識・物体検出・セグメンテーションに利用
  * アプリとしては画像のキャプション生成・画像の生成・強化学習・自動運転

参考文献：ゼロから作るDeep Learning: Pythonで学ぶディープラーニングの理論と実装/2016年/斎藤康毅/O'Reilly Japan
